{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAig2bMgULni9pr02fhDVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitinVerma2027/PRML-Apr2025/blob/main/ml_ipynb_files/Logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "7b77-x3CosOM",
        "outputId": "73014d75-5342-4bec-9489-dff9048770f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1gj1rEzLDzNBpRswfqZaJxCFs5EwQSA87\n",
            "From (redirected): https://drive.google.com/uc?id=1gj1rEzLDzNBpRswfqZaJxCFs5EwQSA87&confirm=t&uuid=e3381cc3-6641-42f8-aaec-80083cb87368\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 110M/110M [00:01<00:00, 79.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
            "0    5    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "2    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "3    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "4    9    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "\n",
            "   779  780  781  782  783  784  \n",
            "0    0    0    0    0    0    0  \n",
            "1    0    0    0    0    0    0  \n",
            "2    0    0    0    0    0    0  \n",
            "3    0    0    0    0    0    0  \n",
            "4    0    0    0    0    0    0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "Total available samples: 60000\n",
            "Training data shape: (48000, 784)\n",
            "Test data shape: (12000, 784)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# File ID from Google Drive\n",
        "file_id = \"1gj1rEzLDzNBpRswfqZaJxCFs5EwQSA87\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Download the file\n",
        "output = \"dataset.csv\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Read CSV into Pandas DataFrame\n",
        "df = pd.read_csv(output, header=None)  # No header in the dataset\n",
        "\n",
        "# Preview dataset structure\n",
        "print(df.head())\n",
        "\n",
        "# Extract labels (first column) and features (remaining columns)\n",
        "y = df.iloc[:, 0].values  # Labels\n",
        "X = df.iloc[:, 1:].values  # Features (pixel values)\n",
        "\n",
        "# Normalize pixel values (0-255 → 0-1)\n",
        "X = X / 255.0\n",
        "\n",
        "# Check available dataset size\n",
        "total_samples = X.shape[0]\n",
        "print(f\"Total available samples: {total_samples}\")\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.8  # Use 80% for training, 20% for testing\n",
        "train_size = int(total_samples * train_ratio)\n",
        "test_size = total_samples - train_size  # Remaining for testing\n",
        "\n",
        "# Split dataset while maintaining class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"Training data shape: {X_train.shape}\")  # Should be around 80% of total samples\n",
        "print(f\"Test data shape: {X_test.shape}\")       # Should be around 20% of total samples\n",
        "\n",
        "# Display some sample images|\n",
        "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(X_train[i].reshape(28, 28), cmap=\"gray\")\n",
        "    ax.set_title(f\"Label: {y_train[i]}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Initialize weights and bias\n",
        "def initialize_parameters(n_features):\n",
        "    w = np.zeros((n_features, 1))  # Column vector for weights\n",
        "    b = 0  # Bias\n",
        "    return w, b\n",
        "\n",
        "# Compute cost (Log Loss)\n",
        "def compute_cost(X, y, w, b):\n",
        "    m = X.shape[0]  # Number of samples\n",
        "    z = np.dot(X, w) + b  # Linear combination\n",
        "    y_pred = sigmoid(z)  # Apply sigmoid\n",
        "\n",
        "    # Clip values to avoid log(0) errors\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "\n",
        "    # Compute cost (Log Loss)\n",
        "    cost = (-1 / m) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "    return cost\n",
        "\n",
        "# Compute gradients\n",
        "def compute_gradients(X, y, w, b):\n",
        "    m = X.shape[0]  # Number of samples\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    dw = (1 / m) * np.dot(X.T, (y_pred - y))  # Gradient for weights\n",
        "    db = (1 / m) * np.sum(y_pred - y)  # Gradient for bias\n",
        "\n",
        "    return dw, db\n"
      ],
      "metadata": {
        "id": "GE3GqLSLh2j7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent\n",
        "def gradient_descent(X, y, w, b, learning_rate, num_iterations):\n",
        "    cost_history = []  # Store cost values\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        dw, db = compute_gradients(X, y, w, b)\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= learning_rate * dw\n",
        "        b -= learning_rate * db\n",
        "\n",
        "        # Compute cost and store it\n",
        "        cost = compute_cost(X, y, w, b)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        # Print cost every 100 iterations\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}: Cost = {cost:.4f}\")\n",
        "\n",
        "    return w, b, cost_history\n"
      ],
      "metadata": {
        "id": "TkKfyeMsh8b6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to One-vs-All format\n",
        "def one_vs_all_labels(y, digit):\n",
        "    return (y == digit).astype(int)  # Convert to binary (1 if digit, 0 otherwise)\n",
        "\n",
        "num_classes = 10\n",
        "num_iterations = 3000\n",
        "learning_rate = 0.1\n",
        "\n",
        "models = []  # Store trained (w, b) for each digit\n",
        "\n",
        "for digit in range(num_classes):\n",
        "    print(f\"Training model for digit {digit} vs. all...\")\n",
        "\n",
        "    # Convert labels for current digit\n",
        "    y_train_digit = one_vs_all_labels(y_train, digit).reshape(-1, 1)\n",
        "    y_test_digit = one_vs_all_labels(y_test, digit).reshape(-1, 1)\n",
        "\n",
        "    # Initialize weights and bias\n",
        "    w, b = initialize_parameters(X_train.shape[1])\n",
        "\n",
        "    # Train logistic regression model\n",
        "    w_trained, b_trained, _ = gradient_descent(X_train, y_train_digit, w, b, learning_rate, num_iterations)\n",
        "\n",
        "    # Store trained model\n",
        "    models.append((w_trained, b_trained))\n"
      ],
      "metadata": {
        "id": "TYgpxsoYh_V6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}